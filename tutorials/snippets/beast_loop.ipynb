{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick MNIST example\n",
    "\n",
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wget in /opt/conda/lib/python3.9/site-packages (3.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install wget\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import torchsummary\n",
    "import wget\n",
    "import tensorboard\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "sys.path.insert(0, os.path.abspath(\"../..\"))\n",
    "\n",
    "import numpy as np\n",
    "import vegans.utils.loading as loading\n",
    "import vegans.utils as utils\n",
    "\n",
    "from vegans.GAN import (\n",
    "    ConditionalAAE,\n",
    "    ConditionalBicycleGAN,\n",
    "    ConditionalEBGAN,\n",
    "    ConditionalKLGAN,\n",
    "    ConditionalLRGAN,\n",
    "    ConditionalLSGAN,\n",
    "    ConditionalPix2Pix,\n",
    "    ConditionalVAEGAN,\n",
    "    ConditionalVanillaGAN,\n",
    "    ConditionalVanillaVAE,\n",
    "    ConditionalWassersteinGAN,\n",
    "    ConditionalWassersteinGANGP,\n",
    ")\n",
    "from vegans.models.conditional.ConditionalVanillaVAE import ConditionalVanillaVAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClearML Task: created new task id=15274dabff724eaba717b9f1b3bfc442\n",
      "CLEARML new package available: UPGRADE to v1.0.3 is recommended!\n",
      "Release Notes:\n",
      "### Features\n",
      "\n",
      "- Use default `boto` credential chain if no keys are provided in the configuration file or environment variables #342\n",
      "- Support `DummyModel` configuration [ClearML Slack thread](https://clearml.slack.com/archives/CTK20V944/p1621469235085400)\n",
      "- Add `report_matplotlib_figure(..., report_interactive=False)` allowing to upload a matplotlib as a non-interactive (high quality png) plot\n",
      "- Add `Logger.matplotlib_force_report_non_interactive()`\n",
      "- Remove matplotlib axis range (`plotly.js` auto-range can adjust it in real-time)\n",
      "- Add object-storage support in cleanup-service\n",
      "- Add `dataset_tags` argument to `Dataset.create()`\n",
      "- Expose `docker_args` and `docker_bash_setup_script` in `clearml-task` CLI\n",
      "- Add logging for Nvidia driver and Cuda version\n",
      "- Add optional ignored packages in script requirements (currently used for `pywin32`)\n",
      "- Update examples\n",
      "  * Increase channel result to support max of 1K channels for finding slack channel and use cursor in Slack Alerts monitoring service\n",
      "  * Add `csv` data sample to `data_samples`\n",
      "  * Remove deprecated examples\n",
      "\n",
      "### Bug Fixes\n",
      "\n",
      "- Fix Hydra should not store the full resolved OmegaConf #327\n",
      "- Fix direct import of keras save/load model functions #355\n",
      "- Fix run as module #359\n",
      "- Fix Python 2.7 support #366\n",
      "- Fix `Task.add_requirements()` passing `package_version` starting with `@`, `;` or `#`\n",
      "- Fix import keras from TF\n",
      "- Fix support for Hydra's `run_job()` change in parameter order by passing `config` and `task_function` as keyword arguments \n",
      "- Fix background upload retries with Google Storage (`gs://`)\n",
      "- Fix Python 3.8 race condition in `Task.close()`\n",
      "- Fix shutting down a Task immediately after creation might block\n",
      "- Fix `Task.execute_remotely()` from Jupyter notebook\n",
      "- Fix Jupyter Notebook inside VSCode\n",
      "- Fix support for `Dataset.create()` argument `use_current_task`\n",
      "- Fix `Dataset.finalize()` can hang in extreme scenario\n",
      "- Protect against wrong file object type when auto-binding models\n",
      "- Fix matplotlib date convertor\n",
      "- Fix automation controller overrides nodes clone\n",
      "ClearML results page: http://clearml.prod.mlops.unit8/projects/991f542f9acc47cab274a2bb3d945428/experiments/15274dabff724eaba717b9f1b3bfc442/output/log\n",
      "2021-06-11 06:45:00,806 - clearml - WARNING - Switching to remote execution, output log page http://clearml.prod.mlops.unit8/projects/991f542f9acc47cab274a2bb3d945428/experiments/15274dabff724eaba717b9f1b3bfc442/output/log\n"
     ]
    }
   ],
   "source": [
    "from clearml import Task\n",
    "task = Task.init('vegans', 'celebA64')\n",
    "task.execute_remotely('gpu_support')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = loading.CelebALoader(batch_size=32, max_loaded_images=5000, output_shape=64)\n",
    "train_dataloader = loader.load()\n",
    "\n",
    "epochs = 6\n",
    "\n",
    "X_train, y_train = iter(train_dataloader).next()\n",
    "X_train, y_train = X_train.numpy(), y_train.numpy()\n",
    "x_dim = X_train.shape[1:]\n",
    "y_dim = y_train.shape[1:]\n",
    "z_dim = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[vegans.models.conditional.ConditionalBicycleGAN.ConditionalBicycleGAN,\n",
       " vegans.models.conditional.ConditionalKLGAN.ConditionalKLGAN,\n",
       " vegans.models.conditional.ConditionalLRGAN.ConditionalLRGAN,\n",
       " vegans.models.conditional.ConditionalLSGAN.ConditionalLSGAN,\n",
       " vegans.models.conditional.ConditionalPix2Pix.ConditionalPix2Pix,\n",
       " vegans.models.conditional.ConditionalVAEGAN.ConditionalVAEGAN,\n",
       " vegans.models.conditional.ConditionalVanillaGAN.ConditionalVanillaGAN,\n",
       " vegans.models.conditional.ConditionalVanillaVAE.ConditionalVanillaVAE,\n",
       " vegans.models.conditional.ConditionalWassersteinGAN.ConditionalWassersteinGAN,\n",
       " vegans.models.conditional.ConditionalWassersteinGANGP.ConditionalWassersteinGANGP,\n",
       " vegans.models.conditional.ConditionalWassersteinGAN.ConditionalWassersteinGAN,\n",
       " vegans.models.conditional.ConditionalWassersteinGANGP.ConditionalWassersteinGANGP]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loader = loading.ExampleLoader()\n",
    "generator = loader.load_generator(x_dim=x_dim, z_dim=z_dim, y_dim=y_dim)\n",
    "discriminator = loader.load_adversary(x_dim=x_dim, y_dim=y_dim, adv_type=\"Discriminator\")\n",
    "critic = loader.load_adversary(x_dim=x_dim, y_dim=y_dim, adv_type=\"Critic\")\n",
    "encoder = loader.load_encoder(x_dim=x_dim, z_dim=z_dim, y_dim=y_dim)\n",
    "decoder = loader.load_decoder(x_dim=x_dim, z_dim=z_dim, y_dim=y_dim)\n",
    "\n",
    "models = [\n",
    "    ConditionalBicycleGAN, ConditionalKLGAN,\n",
    "    #ConditionalLRGAN, ConditionalLSGAN,\n",
    "    #ConditionalPix2Pix, ConditionalVAEGAN, ConditionalVanillaGAN,\n",
    "    #ConditionalVanillaVAE , ConditionalWassersteinGAN, ConditionalWassersteinGANGP,\n",
    "    #ConditionalWassersteinGAN, ConditionalWassersteinGANGP,\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in models:\n",
    "    folder = \"MyModels/{}\".format(model.__name__.replace(\"Conditional\", \"c\"))\n",
    "    kwargs = {\"x_dim\": x_dim, \"z_dim\": z_dim, \"y_dim\": y_dim, \"folder\": folder}\n",
    "\n",
    "    if model.__name__ in [\"ConditionalAAE\"]:\n",
    "        discriminator_aee = loading.ExampleLoader().load_adversary(x_dim=z_dim, y_dim=y_dim, adv_type=\"Discriminator\")\n",
    "        gan_model = model(\n",
    "            generator=generator, adversary=discriminator_aee, encoder=encoder, **kwargs\n",
    "        )\n",
    "\n",
    "    elif model.__name__ in [\"ConditionalBicycleGAN\", \"ConditionalVAEGAN\"]:\n",
    "        encoder_reduced = loader.load_encoder(x_dim=x_dim, z_dim=z_dim*2, y_dim=y_dim)\n",
    "        gan_model = model(\n",
    "            generator=generator, adversary=discriminator, encoder=encoder_reduced, **kwargs\n",
    "        )\n",
    "\n",
    "    elif model.__name__ in [\"ConditionalEBGAN\"]:\n",
    "        m = np.mean(X_train)\n",
    "        gan_model = model(\n",
    "            generator=generator, adversary=autoencoder, m=m, **kwargs\n",
    "        )\n",
    "\n",
    "    elif model.__name__ in [\"ConditionalKLGAN\", \"ConditionalLSGAN\", \"ConditionalPix2Pix\", \"ConditionalVanillaGAN\"]:\n",
    "        gan_model = model(\n",
    "            generator=generator, adversary=discriminator, **kwargs\n",
    "        )\n",
    "\n",
    "    elif model.__name__ in [\"ConditionalLRGAN\"]:\n",
    "        gan_model = model(\n",
    "            generator=generator, adversary=discriminator, encoder=encoder, **kwargs\n",
    "        )\n",
    "\n",
    "    elif model.__name__ in [\"ConditionalVanillaVAE\"]:\n",
    "        encoder_reduced = loader.load_encoder(x_dim=x_dim, z_dim=z_dim*2, y_dim=y_dim)\n",
    "        gan_model = model(\n",
    "            encoder=encoder_reduced, decoder=decoder, **kwargs\n",
    "        )\n",
    "\n",
    "    elif model.__name__ in [\"ConditionalWassersteinGAN\", \"ConditionalWassersteinGANGP\"]:\n",
    "        gan_model = model(\n",
    "            generator=generator, adversary=critic, **kwargs\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        raise NotImplementedError(\"{} no yet implemented in logical gate.\".format(model.__name__))\n",
    "        \n",
    "    gan_model.summary(save=True)\n",
    "    gan_model.fit(\n",
    "        X_train=train_dataloader,\n",
    "        y_train=None,\n",
    "        X_test=None,\n",
    "        y_test=None,\n",
    "        batch_size=8,\n",
    "        epochs=epochs,\n",
    "        steps=None,\n",
    "        print_every=500,\n",
    "        save_model_every=None,\n",
    "        save_images_every=\"0.1e\",\n",
    "        save_losses_every=10,\n",
    "        enable_tensorboard=False\n",
    "    )\n",
    "    samples, losses = gan_model.get_training_results(by_epoch=False)\n",
    "\n",
    "    training_time = np.round(gan_model.total_training_time/60, 2)\n",
    "    title = \"Epochs: {}, z_dim: {}, Time trained: {} minutes\\nParams: {}\\n\\n\".format(\n",
    "        epochs, z_dim, training_time, gan_model.get_number_params()\n",
    "    )\n",
    "    fig, axs = utils.plot_images(images=samples, show=False)\n",
    "    fig.suptitle(title, fontsize=12)\n",
    "    fig.tight_layout()\n",
    "    plt.savefig(gan_model.folder+\"/generated_images.png\")\n",
    "\n",
    "    fig, axs = utils.plot_losses(losses=losses, show=False)\n",
    "    fig.suptitle(title, fontsize=12)\n",
    "    fig.tight_layout()\n",
    "    plt.savefig(gan_model.folder+\"/losses.png\")\n",
    "    task.upload_artifact('LoggedFolder', artifact_object=os.path.join(\"MyModels\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
